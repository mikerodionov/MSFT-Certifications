# AI-900

OD

- Entry-level certification (Fundamentals/900-series), not focused on coding or implementation
- Focus on what technology can do
- AI focus: congnitive services, bots, Azure ML
- Non-AI focus: Microsoft responsible AI principles
- Azure has around 28 cognitive services available

## AI in Azure

### AI overview

AI

- Reasoning - Draw conclusions from imperfect data
- Understanding - Interpret meaning on data such as images, video or audio
- Interacting - Communicate in more natural ways (voice or text)

Common AI wokrloads / Usecases

- Machine learning (prediction/conclusions based on imperfect data - stock price prediction, medical prognosis) / Predictions
- Anomaly detection (credit card fraud detection, equipment failure prediction) / Fraud and failure detection
- Computer vision (interpreting video or image input via classification, object detection or semantic segmentation) / Classify or detect objects
- Natural language processing - NLP (interprent/respond to natural language via key phrase or sentiment detection) / Interpret language
- Converstational AI / Chatbots

AI enablers

- Big data via cheaper and faster storage
- Fast/high compute via GPU and scale-out clusters
- Better algorithms via advancements on AI and ML algorithms

AI entry barriers

- Models are expensive to build, test, and improve (but once built are cheap to consume)
- Entry barriers for smaller companies
- Microsoft strategy for democratizing AI

### Cognitive Services

- Pre-bilt AI models available in Azure
- Allow building AI-infused apps with no ML or AI knowledge
- Highly refined models (Microsoft refined their models on Bing, Skype, X-Box and Cortana)
- Amply programming language support with SDKs and code samples available for .Net, Node.js, Python, Go, Java
- Privacy assured (data not kept after processing, making it easier to comply with data privacy standards such as GDPR; the only exception is some of the Bing APIs where some of the quieries are kept by MSFT to improve their models)
- Low cost, including free tiers

#### Cognitive services pillars

Vision - APIs which can recognize faces, emotions, landmarks, objects & handwriting
Speech - biderectional conversion between text and audio
Language - identify key phrases and understand and translate language
Decision (knowledge) - auotmated choices for content moderation or anomaly detection
Web search - set of Bing APIs for searching web contents

All of the congnitive services pillars/categories have a custom component

- Vision - Custom Vision
- Speech - Speech Studio
- Language - LUIS
- Decision - Content Moderator
- Web Search - Bing Custom Search

#### Congitive Services Decision Workflow

Generic? Y = Use generic service, N = Custom? Y = Use Custom Service, N = Create your own AI model

#### Cognitive Services Lifecycle

- Labs (labs.cognitive.microsoft.com) - can be highly modified before GA or not launched at all (e.g. chatbot personality)
- Public Preview - may change before GA, easy to sign up for (e.g. speaker recognition, anomaly detector)
- GA - generally available service
- Retired/Merged/Branded into new one (e.g. the Emotion API was meged with the Face API)

[Latest set of available cognitive services](https://azure.microsoft.com/en-us/services/cognitive-services)

### The Microsoft responsible AI principles

AI going rouge problem is widely explored in movies.

Microsoft Responsible AI principles

- Fairness (preven biases against certain social groups)
- Reliability and safety (key for medicine, self-driving vehicles)
- Privacy and security (respect for individual privacy, protecting customers' data)
- Inclusiveness (inclusive design practices)
- Transparency (preventing black box effects to fight bias and exclusion practices)
- Accountability (humans is the ultimate responsible for decisions, ability to override AI decision)

## Vision

### Computer Vision

Vision is a set of several APIs related to images and video.

- Computer and Custom Vision
- Face API
- Video Indexer

#### Computer Vision

- Microsoft's general-purpose vision tech allowing to detect elements on a pictures of various formats (JPEG, GIF, PNG, BMP/URL to these files)
- Feature rich API
  - Can identify the main colors on a picture
  - Can give a general description of what the picture is about (several descriptions with their level of confidence can be requested via code)
  - Can identify faces, age, gender and coordinates of the face on the picture (you can detect hair color and emotion with Face API)
  - Thumbnail generation which identifies the most relevant portion of the picture
  - Can generate tags (200), categories (86), brands and objects (10,000+, objects detection is similar tagging but it also identifies bounding box/location of objects on the picture)
  - OCR  (Optical Character Recognition) with support of detecting 25 language and read of handwriting; detect orientation flag option
  - Detection of adult, racy and gory/violent content (with confidence scale up to 100); there is also separate/dedicated service for this - Content Moderator (provides more features and allows to teach the model according to your corporate policies)
  - Can detect whether image is a line drawing (Boolean) or clipart (3 levels from 0 to 3 = non clipart, ambiguous, normal or good clipart)
  - 2 domain-specific models
    - Celebreties recognition (over 200,000 celebrities)
    - Landmarks (Eiffel Tower etc.)

Computer vision is a generic/catch all API.

Catch all mnenonic:

C - Colors and descriptions
A - Age, gender, and face location
T - Thumbnails
C - Categories, tags, brands, and objects
H - Handwriting and OCR
A - Adult, racy, and gory (content detection/moderation)
L - Line drawing and clipart
L - Landmarks and celebrities (via 2 domain-specific models)

### The Face API

Two main functionalities:

#### Face detection

- General attributes: age, gender, smile, hair (color, facial hair)
- Accessories: glasses
- Makeup
- Emotions (neutral, anger, contempt, disgust, fear, happiness, saddness, surprise) with confidence level from 1 to 0 with 1 being the strongest value
- Face landmarks identification - 27 predefined face points "faceline masks" (eyebrow left inner, nose tip, upper lip top, upper lip bottom etc.)

#### Face recognition

- Identify person pictures, face authentication

Configuration flow:

1. Create a person group (or large person group) ~ faces database
  - Standard persons group can hold up to 10,000 persons
  - Large persons group can hold up to a 1,000,000 persons
2. Register each person - add persons you want to identify into the group
3. Upload person face pictures (up to 248 per person - more pictures more precision), you should add front facing pictures, not profile angle ones
4. Train the model

Once configuration/training complete you can call face recognition API for various operations:

- authenticating users
- finding users in pictures
- grouping together pictures belonging to the same face

As with computer vision API you can send either images in a binary format or URLs pointing to the images.

### Form and Ink Recognizer APIs

Computer vision is a catch-all visual API offers some capabilities for forms and reports, bit form recognizer API is a specialized API dedicated to this.

Form Recognizer API

- Custom models (key/calue pair and table data extraction) - can be trained for specific needs of your company
- US receipt format (English)
- Layout API (text and table structures)

Ink Recognizer API

- Ink stroke Input recognition
- Can recognize layot of the image - paragraphs, tables, bulleted lists
- Can recognize basic shapes - circles, rectangles, triangles
- Can recognize which input belongs to a shape and which to handwriting

### Custom Vision

Custom Vision vs. Computer Vision

- Custom Vision allows you train the model to your own needs (e.g. detect clouds on the picture and discern cloud types - cirrus, cumulus, stratus)
- Custom vision offers object detection and object classification
  - Classification
  - Detection - additionally gives a bounding box with location of an object

**Custom vision**

- Interactive portal: www.customvision.ai - to interact with model and train it
- Two separate endpoints and keys - for training and predicition
- Several specialized domains - retail, food, landmarks, logos, products on shelves - use of specific domain improves accuracy
- General domain con be used in case no specialized domain meets your needs
- Supports edge computing (compact models) - enables processing of an image on a device itself (e.g. phone), useful for offline workloads as there is no need to send image to the clous; uses compact domain models to improve model accuracy

#### Custom vision best practices

- Ideally at least 50 images per tag - more images, and more varied they are (background, size, light, angle, style)
- Keep a good balance between the tags (for 50 images of one tag, it is better to have 50 images of another)
- Add negative images which do not belong to any label to improve results
- Fix wrong past predictions to improve the model (via interactive portal)
 
### Vision Cognitive Services

Vision services can be created via Azure Portal - you either create multi-service resourse "Cognitive Services" on a Standard tier or specific resource (Computer Vision).

Cognitive Services
- Pricing Tier

Computer Vision
- Location
- Pricing Tier

Custom Vision - Model can be trained to your needs
- Create new project
  - Project Types - Classification/Object Detection
  - Classification Types - Multilabel (Multiple tags per image)/Multiclass (Single tag per image)
  - Domains - General/Food/Landmarks/Retail or compact versions of those
- Upload training images and tag them - required tags + negative
- Train model once picture uploaded; once done it will show you Precision, Recall and AP with percentage (0 to 100)

Once created you can see service keys and endpoint (KEY1, KEY2, ENDPOINT).

[AI pre-built demos](https://aidemos.microsoft.com)
- Computer Vision - select image and see what Computer Vision can retrieve/detect
- Face API - see what can be detected

### Vision: Additional Resources

[Microsoft Azure AI Fundamentals: Explore computer vision Learning Path](https://aka.ms/explore-computer-vision)
[AI](https://aischool.microsoft.com/en-us/home)
[Azure Cognitive Services documentation](https://docs.microsoft.com/en-us/azure/cognitive-services)
[Microsoft Cognitive Services for Developers: 1 Vision](https://www.linkedin.com/learning/microsoft-cognitive-services-for-developers-1-vision)

## Natural Language Processing

### Natural Language Processing (NLP)

AI that understands written/spoken language.

NLP in Azure

#### Speech

Speech APIs:

- Speech to Text (STT)
- Text to Speech (TTS)
- Speech Translation
- Speaker Recognition - voice recognition authentication
- Speech Services - consolidates all speech services into one API
- Speech Studio Portal - replaces all previously available custom speech solutions
Bing Speech API is depricated and replaced with the services mentioned abovoe

Speech technologies:

- Mature, proven models (proven on tools such as Skype, Xbox, Cortana)
- Low latency
- Up to 45 languages supported
- Natively integrated with Bot Framework

#### Language

- Text Analytics
- Translator and Custom Translator
- LUIS
- QnA Maker

### Speech APIs

#### Speech to Text (STT)

- 3 recognition modes
  - Recognize once - for conversational scenarios of less than 20 seconds
  - Continous - for longer conversations
  - Dictation - interpret words and punctuation
- Handles profanity with 3 modes
  - Raw - allows profanity
  - Masked - masking profanity with asterisks
  - Removed - removes the profanity
- Batch transcription API for audio processing - to transcripe long support calls without need of immediate results
- Speech devices SDK - allows to work with speech enabled devices such as Alexa or Google home

#### Text to Speech (TTS)

- 3 voice types
  - Standard - HQ, available in 75 voices in 45 languages, but intonation is not natural
  - Neural - provide better stress/intonation/fluidity, sound more human like, less number of languages supported
  - Custom - create your own voice models when unique voice is required
- SSML (Speech Synthesis Markup Language) is an XML-based format which is used to configure voice settings
  - Contains text, language and voice to use
  - Controls speed, pitch, volume, pronunciation, pauses, voice changes (some of the features are only available for neuro voices and others only for standard ones)

#### Speech Translation

- 60 languages - several voices and locales, even [Klingon](https://en.wikipedia.org/wiki/Klingon_language)
- Conversion between speech and text
- Translation can be return as text or (optionally) as synthetised voice (not available for all languages)
- Optional profanity handling - raw, masked (default), removed
- Speaker recognition with 2 main components
  - Speaker Verification - authentication purposes
    - Voice enrollment - user sends 3 audios with a specific pass phrase
    - Voice signature generation
    - Voice signature use for access
  - Speaker Identification - recognizing speaker on audio file
    - Identify speaker on audio file (simpler enrollment process - only 1 audio is required witout specific passphrase)

### Speech Services and Speech Studio

#### Speech Services

Speech Services - consolidate all speech APIs into one API.

#### Speech Studio

- Custom speech portal on Azure
- Supports several languages
- Allows to perform a variety of speech customizations
  - Acoustic Models
    - Customized for specific **environment** such as an airport or interior of a car
    - Configured for specific **speaker** e.g. someone with strong accent or a speech impairement
    - Configured for specific **audio equipment** e.g. new microphone device
  - Language Models - industry/jargon optimized (magic, pharma, Sci-Fi)
  - Pronunciation Models - to define pronunciation of certain words (C-3PO, R2-D2, Kubernetes)
  - Voice fonts - unique, HQ model requires at least 8 hours of audio with transcripts

### Language Services

- Language APIs for language understanding
- **Text Analytics** - extracts metadata about the text (keyphrases, entities, sentiment, language)
- **Translator** - can translate up to 70 different languages
- **LUIS (Language Understanding Intelligence Service)** - detects meaning from questions asked in various forms
- **QnA Maker** - allows extraction of question-answer pairs from semi-structured contents (FAQs, product manuals, guidelines etc.)

#### Text Analytics

- Key phrase extraction - tries to understand main topic of the text
- Sentiment analysis - returns sentiment score from 0 to 1 (very unhappy to very happy)
- Language detection - supports over 120 languages to detect message language with confidence score for the language detected
- Entity recognition - identifies entities within sentences (people, places, organizations, currencies etc.); used to be a separate cognitive service under the knowledge pillar

#### Translator API

- Translates into 70+ languages
- Transliterates between alphabets (such as Japanes and Latin)
- Language and sentence length detection
- V3 returns JSON (V2 used to return XML) response
- Custom translator - allows customize translations for specifc company/industry (farmer, automotive), upload specif documents in a pai

#### LUIS

- Accessible via portal - http://luis.ai
- Enables natural language phrase understanding, so that you don't need to code for every single vatiation of the phrase (e.g. Book me a hotel, Find me a room)
- LUIS understanding works through
  - Utterances - Book me a hotel, Find me a room
  - Intents - book, find (verb)
  - Entities - hotel, room (object)
- Excellent with Both Framework - you don't need to develop for every variation of the same intents and entities
- Response returned as JSON array (intents and entities with confidence level)
- Prebuilt models/domains for common topics (restaurant reservation, calendar/mail management, to-do lists)
- One-click integration with Bing Spell Check, sentiment analysis, and speech recognition

### NLP Cognitive Services

https://azure.microsoft.com/en-us/services/cognitive-services/text-to-speech/#features

https://aidemos.microsoft.com/text-analytics

https://www.luis.ai/applications

### NLP: Additional Resources

[Microsoft Azure AI Fundamentals: Explore natural language processing](https://aka.ms/explore-nlp)
[Create a language model with Conversational Language Understanding](https://aka.ms/learn-luis)
[Language â€“ Text Analytics and Beyond](http://aidemos.microsoft.com/text-analytics)
[Translator](https://translate.it)
[Microsoft Cognitive Services for Developers: 2 Speech](https://www.linkedin.com/learning/microsoft-cognitive-services-for-developers-2-speech)
[Microsoft Cognitive Services for Developers: 3 Language](https://www.linkedin.com/learning/microsoft-cognitive-services-for-developers-3-language)

## Creating Bots

### Conversational AI

- The ability of an agent to participate in conversations
- Allow communication with skills familiar to users - speaking/writing instead of interacting with UI
- Good for small set of predefined options
- Bot Framework + Cognitive Services

Responsible AI for Bots

- Transparency about bot capabilities
- Make it clear that user communicates with bot
- Enable human handoff
- Respect cultural norms, privacy, and data security
- Ensure reliability
- Accessibility standards
- Accountability

### Bot Framework

#### Bot Framework

- SDKs for building bots - open-source, available in multiple languages (.NET, JavaScript, Python); introduced in 2016
- Secure (https) and compliant (GDPR, PCI DSS, ISO 27001)
- Bot Connector - code once and deploy to several channels - social networks, websites, chat services (Skype, Slack, Teams etc.)

#### QnA Maker

- Extracts question-answer pairs from semi-structured content (FAQs, product manuals, guidelines, etc.)
- Model improves over time + an option to refresh the content to updated it with new information
- Perfect for bots - considerably increases your Bot's intelligence and capacity to respond to questions
- 3 options to build
  - Data sources - public web pages or documents - service can go through cascading hyperlinks from the pages to obtain additional information
  - Manually - when you have to create new KB from scratch
  - Chit-chat - content not related to a main QnA topic to add more personality to your model (witchy, enthusiastic)
- Allows for 100% code free bots - https://www.qnamaker.ai/
  1) Create KB via Wizard (Azure Portal)
    - Create QnA Maker Instance
    - Add IAM role assignment adding your account into **Cognitive Services QnA Maker Editor role**
  2) Connect QnA Maker instance to KB & select language
  3) Name your KB
  4) Populate your KB
   - Add URLs to files to extract Q&A from online FAQs, product manuals, or files (TSV, PDF, DOCX, XLSX)
   - Optionally enable multi-turn extraction from URLs, PDF, or DOCX files
   - Add predifined chit-chat (None, Professional, Friendly, Witty, Caring, Enthusiastic)
  5) Create your KB
  - Once KB is created you can manually add additional Q&A pairs
  - Save & Train
  - Test
  - Once KB is published you can create Bot based on this KB, selecting C# or Node.js (although we didn't use code to create bot we may want later adjust the code)
  - Once bot is created we have "Test in Web Chat" UI within Azure Portal to test it
  - Under bot channels we have options to connect it to channels (Web Chat, Teams, Skype, Slack, etc.)

### Conversational AI: Additional Resources

[Build a bot with the Language Service and Azure Bot Service](https://aka.ms/learn-qa-bot)
[Azure Health Both](https://microsoft.com/research/project/health-bot)
[Intermediate Bot Framework for Developers](https://www.linkedin.com/learning/intermediate-bot-framework-for-developers)

## Working with ML Solutions

### Intro to ML Solutions

#### 5 questions data science can answer

1) Classification - A or B? Is this machine supposed to fail within 30 days - Y/N? - Dual class classification; in case of more than 2 possible options it is called multiclass classification
2) Regression - How much/many? Here we generally looking for a number. Total number of sales for company X in the year Y.
3) Anomaly detection - Is this weird? Looking for data that stands out of a pattern. Useful for IT security (anomal activity on account) or bank fraud detection.
4) Clustering - which groups? How this organized? E.g. recommended for you section on website
5) Reinforcement - What's next?

ML is a technique used to create predictive models that respond to the questions above by inferring relationships on the data.

Variable which has influence on the outcome/value we trying to predict called **feature** in ML terms. And outcome/value we are trying to predict is called a **label**.


### Classification models on Azure ML

### Create a custom Azure ML resource

### Automated ML

### Azure ML: Additional resources